{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and Embedding Wikipedia Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The parquet file containing the 10,000 wikipedia articles contains 700,000+ rows of text data. This demo file simply embeds a small sample of rows (1,000) using BERT, then it runs a vector similarity search using FAISS. The working BERT -> FAISS pipeline should involve grouping the rows of text with their appropriate articles and efficiently running the embedding on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_rows(parquet_file_path):\n",
    "    table = pq.read_table(parquet_file_path)\n",
    "    return table.num_rows\n",
    "\n",
    "def sample_parquet_data(parquet_file_path, sample_size):\n",
    "    total_rows = get_total_rows(parquet_file_path)\n",
    "    \n",
    "    if sample_size >= total_rows:\n",
    "        print(f\"Sample size {sample_size} is >= total rows {total_rows}. Processing all data.\")\n",
    "        return pq.read_table(parquet_file_path).to_pandas()\n",
    "    \n",
    "    print(f\"Sampling {sample_size} rows from {total_rows} total rows...\")\n",
    "    # Sample indices\n",
    "    sampled_indices = np.random.choice(total_rows, size=sample_size, replace=False)\n",
    "    sampled_indices.sort()  # Sort for efficient reading\n",
    "    \n",
    "    # Read the entire table and filter by sampled indices\n",
    "    table = pq.read_table(parquet_file_path)\n",
    "    sampled_table = table.take(sampled_indices)  # Take rows at the sampled indices\n",
    "    return sampled_table.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_data(df):\n",
    "    \"\"\"\n",
    "    Print information about the dataframe and display the first few rows.\n",
    "    \"\"\"\n",
    "    print(\"\\nData Inspection:\")\n",
    "    print(f\"Shape of the dataframe: {df.shape}\")\n",
    "    print(\"\\nColumn names:\")\n",
    "    print(df.columns.tolist())\n",
    "    print(\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nSample of text data:\")\n",
    "    print(df.iloc[0, 0])  # Assuming text is in the first column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text_batch(text_batch, batch_size=32):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(text_batch), batch_size):\n",
    "            batch = text_batch[i:i+batch_size]\n",
    "            inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            outputs = model(**inputs)\n",
    "            cls_embedding = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "            embeddings.append(cls_embedding)\n",
    "    return np.concatenate(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_embed_data(parquet_file_path, output_file_path, sample_size=10000, embedding_batch_size=32):\n",
    "    print(f\"Sampling and loading data...\")\n",
    "    start_time = time.time()\n",
    "    sampled_data = sample_parquet_data(parquet_file_path, sample_size)\n",
    "    print(f\"Data sampled and loaded in {time.time() - start_time:.2f} seconds\")\n",
    "    \n",
    "    inspect_data(sampled_data)\n",
    "    \n",
    "    user_input = input(\"\\nDo you want to continue with the embedding process? (yes/no): \").lower()\n",
    "    if user_input != 'yes':\n",
    "        print(\"Embedding process cancelled.\")\n",
    "        return\n",
    "\n",
    "    all_embeddings = []\n",
    "    texts = sampled_data.iloc[:, 0].tolist()  # Assuming text is in the first column\n",
    "    \n",
    "    print(f\"Embedding {len(texts)} texts...\")\n",
    "    for i in tqdm(range(0, len(texts), embedding_batch_size), desc=\"Processing batches\"):\n",
    "        batch = texts[i:i+embedding_batch_size]\n",
    "        batch_embeddings = embed_text_batch(batch, batch_size=embedding_batch_size)\n",
    "        all_embeddings.append(batch_embeddings)\n",
    "    \n",
    "    print(\"Concatenating all embeddings...\")\n",
    "    final_embeddings = np.concatenate(all_embeddings)\n",
    "    \n",
    "    print(f\"Saving embeddings to {output_file_path}...\")\n",
    "    np.save(output_file_path, final_embeddings)\n",
    "    print(f\"Embeddings saved. Shape of embeddings: {final_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting process with parquet file: c:\\Users\\chand\\ACME10-HE-RAGApp\\src\\data\\simpleWikiData.parquet\n",
      "Sampling and loading data...\n",
      "Sampling 1000 rows from 769764 total rows...\n",
      "Data sampled and loaded in 0.16 seconds\n",
      "\n",
      "Data Inspection:\n",
      "Shape of the dataframe: (1000, 1)\n",
      "\n",
      "Column names:\n",
      "['text']\n",
      "\n",
      "Data types:\n",
      "text    object\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n",
      "                                                text\n",
      "0  This kind of intensive agriculture comes with ...\n",
      "1  Farmers select plants with better yield, taste...\n",
      "2  As of 2004, there are thirty-four provinces. E...\n",
      "3  E2 users create pages called \"nodes\" and add s...\n",
      "4  Not all paradoxes are true logical paradoxes, ...\n",
      "\n",
      "Sample of text data:\n",
      "This kind of intensive agriculture comes with its own set of problems. Farmers use a lot of chemical fertilizers, pesticides (chemicals that kill bugs), and herbicides (chemicals that kill weeds). These chemicals can pollute the soil or the water. They can also create bugs and weeds that are more resistant to the chemicals, causing outbreaks of these pests. The soil can be damaged by erosion (blowing or washing away), salt buildup, or loss of structure. Irrigation (adding water from rivers) can pollute water and lower the water table. These problems have all got solutions, and modern young farmers usually have a good technical education.\n",
      "Embedding 1000 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 32/32 [01:26<00:00,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating all embeddings...\n",
      "Saving embeddings to wikipedia_embeddings_sample.npy...\n",
      "Embeddings saved. Shape of embeddings: (1000, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "parquet_file_path = os.path.abspath('../../src/data/simpleWikiData.parquet')\n",
    "output_file_path = 'wikipedia_embeddings_sample.npy'\n",
    "print(f\"Starting process with parquet file: {parquet_file_path}\")\n",
    "\n",
    "# You can adjust these parameters\n",
    "sample_size = 1000  # Adjust this to your desired sample size\n",
    "embedding_batch_size = 32\n",
    "\n",
    "process_and_embed_data(parquet_file_path, output_file_path, sample_size=sample_size, embedding_batch_size=embedding_batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Similarity Search Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings shape: (1000, 768)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the embeddings\n",
    "output_file_path = 'wikipedia_embeddings_sample.npy'\n",
    "embeddings = np.load(output_file_path)\n",
    "\n",
    "print(f\"Loaded embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Assuming your embeddings have shape (num_vectors, dim)\n",
    "dim = embeddings.shape[1]  # Number of dimensions\n",
    "\n",
    "# Create a FAISS index (L2 distance)\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "\n",
    "# Add your embeddings to the index\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors (indices): [[ 0  1 58  7 30]]\n",
      "Distances to nearest neighbors: [[ 0.      71.1909  71.89008 76.17949 76.93776]]\n"
     ]
    }
   ],
   "source": [
    "# Select a query vector (for example, the first embedding)\n",
    "query_vector = embeddings[0].reshape(1, -1)  # Reshape to (1, dim)\n",
    "\n",
    "# Number of nearest neighbors to search for\n",
    "k = 5  # You can change this to find more neighbors\n",
    "\n",
    "# Perform the search\n",
    "distances, indices = index.search(query_vector, k)\n",
    "\n",
    "# Output the results\n",
    "print(\"Nearest neighbors (indices):\", indices)\n",
    "print(\"Distances to nearest neighbors:\", distances)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
